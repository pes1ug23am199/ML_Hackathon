# ğŸ§  Hackman â€” Intelligent Hangman Agent
### UE23CS352A: Machine Learning Hackathon

**Hackman** is an intelligent Hangman-solving agent that combines probabilistic reasoning (Hidden Markov Model) and reinforcement learning (Q-Learning) to guess words efficiently and accurately. The goal is to design an AI system that learns to play Hangman by leveraging language patterns and decision-based learning.

## ğŸ“˜ Project Overview
The project builds a hybrid model:  
1. An **HMM** trained on a 50,000-word corpus to estimate letter probabilities based on the current masked pattern.  
2. A **Reinforcement Learning Agent** that uses those probabilities to make optimal guesses and minimize wrong attempts.

## ğŸ§  System Architecture
**Hidden Markov Model (HMM):** Trained on `corpus.txt` to learn letter dependencies and transitions. Hidden states represent unknown letters; emissions represent observed ones. The HMM outputs a probability distribution over Aâ€“Z based on the current masked pattern.  
**Reinforcement Learning Agent (Q-Learning):** Learns to make optimal guesses through interaction with a Hangman environment and integrates HMM probabilities as priors for informed decision-making.

## ğŸ§© State, Actions, and Rewards
**State Representation:** `(masked pattern, guessed letters, remaining lives, HMM probabilities)`  
**Actions:** 26 possible actions â€” guessing any unused letter from Aâ€“Z.  
**Reward Function:**
| Event | Reward |
|--------|--------|
| Correct guess | +10 |
| Wrong guess | âˆ’5 |
| Repeated guess | âˆ’2 |
| Word solved | +50 |
| Game lost | âˆ’50 |

This reward system promotes accuracy, discourages repetition, and rewards successful word completion.

## âš™ï¸ Exploration Strategy
An **Îµ-greedy** policy manages exploration vs exploitation. Training begins with **Îµ = 0.6** and gradually decays to **Îµ = 0.05** using a decay rate of **0.9995 per episode**, allowing the agent to explore more in early stages and exploit learned strategies later.

## ğŸ§© Implementation Components
- **BigramHMM:** Learns letter-to-letter transitions and provides posterior probabilities for next guesses.  
- **HangmanEnv:** Custom environment handling word generation, guesses, and game rules.  
- **QLearningAgent:** Learns Q-values from rewards, updates policy, and balances exploration/exploitation.  
- **Training Loop:** Simulates multiple games to train the agent.  
- **Evaluation:** Tests on unseen words using the scoring formula:  
`Final Score = (Success Rate Ã— 2000) âˆ’ (Wrong Guesses Ã— 5) âˆ’ (Repeated Guesses Ã— 2)`

## ğŸ“Š Results and Insights
- The agent learns meaningful linguistic patterns such as prioritizing vowels.  
- HMM integration improved convergence speed and reduced random guessing.  
- Reward shaping and Îµ-decay produced a stable success rate of over 50% on unseen test words.  
- Visualizations show smoother reward trends and declining exploration rates over time.

## ğŸš€ Future Improvements
- Replace Q-table with a **Deep Q-Network (DQN)** for larger state spaces.  
- Dynamically update HMM probabilities after each guess.  
- Introduce **curriculum learning** from short-to-long words.  
- Use **n-gram** or **transformer-based models** for richer context.  
- Parallelize training for faster convergence.

## ğŸ§­ Steps to Run
### 1ï¸âƒ£ Prerequisites
Install Python 3.8+ and required libraries:
```bash
pip install numpy matplotlib
```

### 2ï¸âƒ£ Prepare Data
Ensure these files are in the working directory:
```bash
corpus.txt
test.txt
```
### 3ï¸âƒ£ Run the Program
Execute:
```bash
python main.py
```

### This will:
- Train the HMM on the corpus.  
- Train the Q-Learning agent for **8000 episodes**.  
- Evaluate the agent on **2000 test words**.  
- Display **training and evaluation visualizations**.

---

### 4ï¸âƒ£ Outputs
- **Training progress logs**  
- **Four plots:**
  - Reward per Episode  
  - Epsilon Decay  
  - Smoothed Reward Curve  
  - Evaluation Summary  
- **Evaluation metrics:**
  - Success Rate  
  - Wrong Guesses  
  - Repeated Guesses  
  - Final Score  

---

## ğŸ“ Project Structure
```bash
â”œâ”€â”€ main.ipynb
â”œâ”€â”€ corpus.txt
â”œâ”€â”€ test.txt
â”œâ”€â”€ Analysis_Report.pdf
â”œâ”€â”€ Problem_Statement.pdf
â””â”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## ğŸ‘¥ Authors
Developed as part of **UE23CS352A: Machine Learning Hackathon**  
**Project Title:** *Hackman â€” Hybrid HMM + RL Hangman Agent*  

- [@pes1ug23am199](https://github.com/pes1ug23am199)  
- [@pes1ug23am221](https://github.com/pes1ug23am221)  
- [@pes1ug23am232](https://github.com/pes1ug23am232)  
- [@pes1ug23am203](https://github.com/pes1ug23am203)

---

## ğŸ Acknowledgements
- Department of Computer Science and Engineering(AI & ML)  
